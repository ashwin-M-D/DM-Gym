{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f37fc46",
   "metadata": {},
   "source": [
    "# K-Clustering using Reinforcement Learning\n",
    "\n",
    "## DM-Gym prototype testing\n",
    "\n",
    "### By Ashwin Devanga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dm-gym\n",
    "!pip install ray[default] ray[rllib] ray[tune]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e1c8a",
   "metadata": {},
   "source": [
    "#### Import Base Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb31e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3595ad4",
   "metadata": {},
   "source": [
    "#### import datamining gym packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd9c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dm_gym.utils.data_gen import data_gen_clustering\n",
    "from dm_gym.create_env import ray_create_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1965e5",
   "metadata": {},
   "source": [
    "#### import ray packages for prebuilt RL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import ray\n",
    "from ray.rllib import agents\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a77b5",
   "metadata": {},
   "source": [
    "#### Function to register environment with ray[tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6776a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_env(env_name, env_config={}):\n",
    "    env = ray_create_env(env_name)\n",
    "    tune.register_env(env_name, \n",
    "        lambda env_name: env(env_name,\n",
    "            env_config=env_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you want to use a custom directory to store ray results. The default directory is root/ray_results/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.logger import Logger, UnifiedLogger\n",
    "import os\n",
    "import datetime\n",
    "import tempfile\n",
    "\n",
    "def custom_log_creator(custom_path, custom_str):\n",
    "\n",
    "    timestr = datetime.datetime.today().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    logdir_prefix = \"{}_{}\".format(custom_str, timestr)\n",
    "\n",
    "    def logger_creator(config):\n",
    "\n",
    "        if not os.path.exists(custom_path):\n",
    "            os.makedirs(custom_path)\n",
    "        logdir = tempfile.mkdtemp(prefix=logdir_prefix, dir=custom_path)\n",
    "        return UnifiedLogger(config, logdir, loggers=None)\n",
    "\n",
    "    return logger_creator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c165e",
   "metadata": {},
   "source": [
    "#### Sample Data Generation (Simulated data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08150fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 ###Number of dimentions in the data\n",
    "k = 3 ###Number of clusters we want in the data\n",
    "\n",
    "num_records = 150\n",
    "parameter_means = []\n",
    "parameter_sd = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52859565",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = data_gen_clustering()\n",
    "\n",
    "error, error_code, pm, psd = data_gen.param_init(n=n, k=k, num_records=num_records,\n",
    "                                                 parameter_means=parameter_means, parameter_sd=parameter_sd)\n",
    "data = data_gen.gen_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bef6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the data\n",
    "plt.scatter(data[1], data[2])\n",
    "plt.savefig(\"data_plotted.svg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a355bb99",
   "metadata": {},
   "source": [
    "#### Run Mean-Shift model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483854f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df, coords = data_gen.gen_model(data)\n",
    "for cls in final_df['Class'].unique():\n",
    "    plt.scatter(final_df[final_df['Class'] == cls][1], final_df[final_df['Class'] == cls][2])\n",
    "plt.savefig(\"expected_output.svg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run K-Means clustering model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df, coords = data_gen.gen_model_Kmeans(data)\n",
    "for cls in final_df['Class'].unique():\n",
    "    plt.scatter(final_df[final_df['Class'] == cls][1], final_df[final_df['Class'] == cls][2])\n",
    "plt.savefig(\"expected_output.svg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b797a4",
   "metadata": {},
   "source": [
    "#### Model and environment configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e0383",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"clustering-v3\"\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "num_timesteps = 1000\n",
    "\n",
    "env_config = {\n",
    "    'data': data,\n",
    "    'k': k,\n",
    "}\n",
    "\n",
    "\n",
    "rl_config = dict(\n",
    "    log_level = \"ERROR\",\n",
    "    env=env_name,\n",
    "    \n",
    "    num_workers=0,\n",
    "    num_gpus=0,\n",
    "    \n",
    "    env_config=env_config,\n",
    "\n",
    "    double_q=True,\n",
    "    model=dict(\n",
    "        vf_share_layers=False,\n",
    "        fcnet_activation='relu',\n",
    "        fcnet_hiddens=[128, 64]\n",
    "    ),\n",
    "    exploration_config={\n",
    "        \"type\": \"EpsilonGreedy\",\n",
    "        \"initial_epsilon\": 1.0,\n",
    "        \"final_epsilon\": 0.02,\n",
    "        \"epsilon_timesteps\": 0.4*num_timesteps*epochs,\n",
    "    },\n",
    "    evaluation_config={\n",
    "        \"explore\": False,\n",
    "    },\n",
    "    gamma = 0.4,\n",
    "    target_network_update_freq=500,\n",
    "    buffer_size=1,\n",
    "    #adam_epsilon=1e-8,\n",
    "    #grad_clip=40,\n",
    "    train_batch_size=1,\n",
    "    framework='torch',\n",
    "    lr=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae1250",
   "metadata": {},
   "source": [
    "#### Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use tensorboard to monitor the training.\n",
    "\n",
    "# Comment out the below line to use the default ray results directory\n",
    "#ray_results_dir = \"./ray_results\"\n",
    "\n",
    "## On google colab, uncomment this:\n",
    "\n",
    "%load_ext tensorboard \n",
    "%tensorboard --logdir ~/ray_results\n",
    "\n",
    "## To run locally, paste the below command\n",
    "#  in your terminal to start the server:\n",
    "\n",
    "#tensorboard --logdir \"./ray_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc11d99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Register environment\n",
    "ray.shutdown()\n",
    "register_env(env_name, env_config)\n",
    "\n",
    "# Initialize Ray and Build Agent\n",
    "info = ray.init(num_cpus=1, num_gpus=0, ignore_reinit_error=True, log_to_driver=False)\n",
    "print(\"Dashboard URL: http://{}\".format(info[\"webui_url\"]))\n",
    "\n",
    "try:\n",
    "    ## Use this to change the directory where ray results are stored\n",
    "    agent = agents.dqn.DQNTrainer(env=env_name, config=rl_config, logger_creator=custom_log_creator(os.path.expanduser(ray_results_dir), env_name))\n",
    "except:\n",
    "    ## Use this for default ray_results storage\n",
    "    agent = agents.dqn.DQNTrainer(env=env_name, config=rl_config)\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "rew = np.nan\n",
    "\n",
    "pbar = tqdm(range(epochs), desc='Training Loop' )\n",
    "\n",
    "for i in pbar:\n",
    "    res = agent.train()\n",
    "    results.append(res)\n",
    "    rew = res['episode_reward_mean']\n",
    "    pbar.set_description(\"reward = %f\" % rew)\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29137bb6",
   "metadata": {},
   "source": [
    "#### Plot Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f48be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Unpack values from each iteration\n",
    "rewards = np.hstack([i['episode_reward_mean'] \n",
    "    for i in results])\n",
    "\n",
    "p = 50\n",
    "mean_rewards = np.array([np.mean(rewards[i-p:i+1]) \n",
    "                if i >= p else np.mean(rewards[:i+1]) \n",
    "                for i, _ in enumerate(rewards)])\n",
    "std_rewards = np.array([np.std(rewards[i-p:i+1])\n",
    "               if i >= p else np.std(rewards[:i+1])\n",
    "               for i, _ in enumerate(rewards)])\n",
    "\n",
    "plt.fill_between(np.arange(len(mean_rewards)), \n",
    "                 mean_rewards - std_rewards, \n",
    "                 mean_rewards + std_rewards, \n",
    "                 label='Standard Deviation', alpha=0.3)\n",
    "plt.plot(mean_rewards, label='Mean Rewards')\n",
    "plt.ylabel('Rewards')\n",
    "plt.xlabel('Episode')\n",
    "plt.title('Training Rewards')\n",
    "plt.legend()\n",
    "plt.savefig(\"Results_Rewards.svg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffbc905",
   "metadata": {},
   "source": [
    "#### Plot Loss (td error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d795cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Unpack values from each iteration\n",
    "td_err = [\n",
    "    i['info']['learner']['default_policy']['mean_td_error'] \n",
    "    for i in results]\n",
    "\n",
    "\n",
    "p = 50\n",
    "\n",
    "mean_td_err = np.array([np.mean(td_err[i-p:i+1]) \n",
    "                if i >= p else np.mean(td_err[:i+1]) \n",
    "                for i, _ in enumerate(td_err)])\n",
    "std_td_err = np.array([np.std(td_err[i-p:i+1])\n",
    "               if i >= p else np.std(td_err[:i+1])\n",
    "               for i, _ in enumerate(td_err)])\n",
    "\n",
    "plt.fill_between(np.arange(len(mean_td_err)), \n",
    "                 mean_td_err - std_td_err, \n",
    "                 mean_td_err + std_td_err, \n",
    "                 label='Standard Deviation', alpha=0.3)\n",
    "plt.plot(mean_td_err, label='Mean td_err')\n",
    "plt.ylabel('td_err')\n",
    "plt.xlabel('Episode')\n",
    "plt.title('Training td_err')\n",
    "plt.legend()\n",
    "plt.savefig(\"Results_TD_err.svg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047437b2",
   "metadata": {},
   "source": [
    "#### Run the agent through the data to check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae44df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = []\n",
    "observations = []\n",
    "for i in range(len(data.index)):\n",
    "    obs = data.iloc[[i]].values.tolist()\n",
    "    action = agent.compute_action(obs)\n",
    "    actions.append(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971683bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Plot final output\n",
    "from copy import deepcopy\n",
    "final_df = deepcopy(data)\n",
    "final_df['action'] = actions\n",
    "for cls in final_df['action'].unique():\n",
    "    plt.scatter(final_df[final_df['action'] == cls][1], final_df[final_df['action'] == cls][2])\n",
    "plt.savefig(\"rl_predicted_output.svg\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dab403dcfa4a64bee3ff417c650bc5376500f360e3ead239cab01b685475af7b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
